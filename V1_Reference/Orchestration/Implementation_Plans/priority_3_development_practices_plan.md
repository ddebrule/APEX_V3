# Priority 3: Advanced Development Practices & Quality Engineering

**Status:** ğŸ“‹ DEFERRED (Until needed - see Implementation Triggers below)
**Created:** 2025-12-28
**Deferred:** 2025-12-28 (User decision: Focus on features, not infrastructure)
**Effort:** Medium (4-6 hours across multiple sessions, focused on high-value tasks)
**Breaking Changes:** No
**Dependencies:** Priority 2 âœ… COMPLETED

---

## âš ï¸ IMPLEMENTATION TRIGGERS - When to Revisit This Plan

**Do NOT implement Priority 3 unless you hit one of these triggers:**

### Trigger 1: Production Pain Points ğŸš¨
**Symptoms:**
- Production errors that are hard to debug or reproduce
- Users reporting bugs with unclear context
- "It works on my machine" scenarios

**Immediate Action:** Implement Sentry error tracking + Structured logging (1 hour)

### Trigger 2: Growing Contributor Base ğŸ‘¥
**Symptoms:**
- Onboarding 2+ new contributors to the project
- Frequent questions about "how does this code work?"
- Contributors breaking unwritten conventions

**Immediate Action:** Create MkDocs documentation + Contributor guide (2-3 hours)

### Trigger 3: Code Quality Issues ğŸ›
**Symptoms:**
- Regularly committing code with formatting/linting errors
- Security vulnerabilities discovered in dependencies
- Inconsistent code style across files

**Immediate Action:** Set up pre-commit hooks + Dependabot (1 hour)

### Trigger 4: Major Refactoring or Architecture Changes ğŸ—ï¸
**Symptoms:**
- Planning significant changes to codebase structure
- Need confidence that changes won't break existing functionality
- Fear of breaking something when touching old code

**Immediate Action:** Expand test coverage + Integration tests (3-4 hours)

---

## Quick-Start Options (When Triggered)

**Option 1: Minimal (1 hour)**
- Sentry error tracking
- Dependabot security updates

**Option 2: Recommended (2-3 hours)**
- Option 1 + Pre-commit hooks + Structured logging

**Option 3: Full Setup (8-12 hours across multiple sessions)**
- All Phase 1-4 components below

---

## Overview

Priority 3 elevates A.P.E.X. to world-class professional development standards with **pragmatic, high-value improvements**:
- Automated code quality and security
- Error tracking (know when it crashes)
- Gradual documentation improvements
- Testing infrastructure

**Philosophy:** Focus on tools that catch bugs early and provide real value. Avoid over-engineering.

**Key Design Principles:**
1. **"Leak-Proof" Documentation** - Enforce on new/modified code only, not legacy backfill
2. **Error Tracking First** - Knowing WHEN it crashes > knowing HOW FAST it runs
3. **Pragmatic Testing** - 40-60% coverage goal, not obsessive 100%
4. **Windows-Aware Tooling** - Account for development environment realities

---

## Task Breakdown

### Task 1: Comprehensive Documentation System
**Why:** Enable new contributors, document architectural decisions, create searchable knowledge base

**Effort:** 2-3 hours
**Priority:** HIGH

#### 1.1 Add Docstring Coverage (Leak-Proof Policy)
**Target:** NEW code and MODIFIED files only (not legacy code backfill)

**Philosophy:** "Leak-proof" approach - enforce on new/changed code, don't halt work to document everything

**Standard:** Google-style docstrings
```python
def parse_setup_sheet(pdf_path: str, brand: str) -> dict:
    """Parse RC setup sheet PDF into standardized 24-parameter schema.

    Args:
        pdf_path: Absolute path to PDF file
        brand: Vehicle brand (tekno, associated, mugen, xray)

    Returns:
        Dictionary with 24 setup parameters (DF, DC, DR, SO_F, etc.)

    Raises:
        FileNotFoundError: If PDF doesn't exist
        ValueError: If brand is unsupported

    Example:
        >>> setup = parse_setup_sheet("tekno_nb48.pdf", "tekno")
        >>> setup["DF"]
        '7000'
    """
```

**Enforcement Strategy:**
1. **Pre-commit hook** checks only files in current commit (not entire codebase)
2. **CI/CD** validates docstrings on changed files only
3. **Gradual improvement** as code is naturally touched during feature work

**Priority Files** (document when next modified):
- `Execution/services/setup_parser.py` - PDF parsing logic
- `Execution/services/history_service.py` - Memory retrieval queries
- `Execution/ai/prompts.py` - AI prompt templates
- `Execution/database/database.py` - Connection management

**Tool:** `pydocstyle` for validation (on changed files only)
```bash
pip install pydocstyle
# Only check files in git diff (not entire codebase)
git diff --name-only --diff-filter=AM | grep '\.py$' | xargs pydocstyle --convention=google
```

**Pre-commit Configuration** (selective):
```yaml
# .pre-commit-config.yaml
- repo: https://github.com/pycqa/pydocstyle
  rev: 6.3.0
  hooks:
    - id: pydocstyle
      args: ["--convention=google"]
      # Only runs on staged files, not entire codebase
```

#### 1.2 API Documentation with MkDocs
**Tool:** MkDocs with Material theme (easier setup, modern look vs. Sphinx)

**Why MkDocs over Sphinx:**
- Faster setup (5 minutes vs. 30 minutes)
- More modern UI out-of-the-box
- Markdown-based (simpler than reStructuredText)
- Better for application docs (Sphinx better for scientific/library docs)

**Setup:**
```bash
pip install mkdocs mkdocs-material mkdocstrings[python]
mkdocs new .
# Creates docs/ directory with mkdocs.yml
```

**Configuration:** `mkdocs.yml`
```yaml
site_name: A.P.E.X. Documentation
site_description: RC Racing Performance Engineering System
theme:
  name: material
  palette:
    primary: indigo
    accent: orange
  features:
    - navigation.instant
    - navigation.tracking
    - search.suggest

plugins:
  - search
  - mkdocstrings:
      handlers:
        python:
          options:
            docstring_style: google

nav:
  - Home: index.md
  - Getting Started:
      - Quick Start: getting-started/quickstart.md
      - Installation: getting-started/installation.md
  - User Guide:
      - Dashboard Overview: guide/dashboard.md
      - Setup Parsing: guide/setup-parsing.md
      - AI Advisor: guide/ai-advisor.md
  - API Reference:
      - Services: api/services.md
      - Database: api/database.md
      - AI Components: api/ai.md
  - Architecture:
      - D.O.E. Framework: architecture/doe-framework.md
      - Data Flow: architecture/data-flow.md
      - Decisions: architecture/decisions.md
  - Development:
      - Contributing: development/contributing.md
      - Testing: development/testing.md
```

**Structure:**
```
docs/
â”œâ”€â”€ index.md                   # Homepage
â”œâ”€â”€ getting-started/
â”‚   â”œâ”€â”€ quickstart.md          # 5-minute setup
â”‚   â””â”€â”€ installation.md        # Detailed install
â”œâ”€â”€ guide/
â”‚   â”œâ”€â”€ dashboard.md           # Dashboard walkthrough
â”‚   â”œâ”€â”€ setup-parsing.md       # How to parse setup sheets
â”‚   â””â”€â”€ ai-advisor.md          # Using the AI advisor
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ services.md            # Services layer API
â”‚   â”œâ”€â”€ database.md            # Database layer API
â”‚   â””â”€â”€ ai.md                  # AI components API
â”œâ”€â”€ architecture/
â”‚   â”œâ”€â”€ doe-framework.md       # 3-layer architecture
â”‚   â”œâ”€â”€ data-flow.md           # Digital Twin pattern
â”‚   â””â”€â”€ decisions/             # ADRs
â”‚       â”œâ”€â”€ 001-database-jsonb.md
â”‚       â”œâ”€â”€ 002-institutional-memory.md
â”‚       â””â”€â”€ 003-hybrid-parsing.md
â””â”€â”€ development/
    â”œâ”€â”€ contributing.md        # Contribution guide
    â””â”€â”€ testing.md             # Testing guide
```

**Build Commands:**
```bash
# Local preview (auto-reload)
mkdocs serve
# Opens http://127.0.0.1:8000

# Build static site
mkdocs build
# Output: site/ directory
```

**Hosting:** GitHub Pages (one command deploy)
```bash
mkdocs gh-deploy
# Automatically builds and pushes to gh-pages branch
```

#### 1.3 Architecture Decision Records (ADRs)
**Purpose:** Document major architectural choices with context and rationale

**Template:**
```markdown
# ADR-001: Use JSONB for Setup Storage in PostgreSQL

## Status
Accepted (2025-12-26)

## Context
Setup sheets have 24 parameters today, but brands constantly add new parameters (e.g., front/rear hubs, chassis stiffeners). Rigid column-based schema requires migrations for each new parameter.

## Decision
Store setup parameters as JSONB column in PostgreSQL instead of 24 individual columns.

## Consequences
**Positive:**
- Add new parameters without schema migrations
- Flexible for future brand variations
- GIN indexes enable fast JSONB queries
- Backward compatible with CSV fallback

**Negative:**
- Type safety moved to application layer
- Slightly slower queries vs. native columns (negligible in practice)

## Alternatives Considered
- 24 individual columns (rejected: inflexible)
- EAV table (rejected: query complexity)
- NoSQL database (rejected: relational features needed)
```

**Initial ADRs to Write:**
1. `001-database-jsonb.md` - Why JSONB for setups
2. `002-institutional-memory.md` - Design of history service
3. `003-hybrid-parsing.md` - PDF + Vision approach
4. `004-doe-framework.md` - Why Directives/Orchestration/Execution naming
5. `005-csv-fallback.md` - Local development strategy

#### 1.4 Developer Onboarding Guide
**Create:** `Orchestration/Onboarding/CONTRIBUTOR_GUIDE.md`

**Sections:**
- Environment setup (5-minute quick start)
- Project architecture overview
- Code contribution workflow
- Testing requirements
- Code style guidelines
- Common pitfalls and debugging tips

---

### Task 2: Enhanced Testing Infrastructure
**Why:** Increase confidence in changes, enable safe refactoring, catch regressions early

**Effort:** 2-3 hours
**Priority:** HIGH

#### 2.1 Expand Unit Test Coverage
**Current Coverage:** ~20% (setup_parser.py only)
**Target Coverage:** 40-60% (pragmatic, not obsessive)

**Priority Test Files:**
```
tests/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ test_setup_parser.py         âœ… EXISTS
â”‚   â”œâ”€â”€ test_liverc_harvester.py     ğŸ†• NEW
â”‚   â”œâ”€â”€ test_history_service.py      ğŸ†• NEW
â”‚   â”œâ”€â”€ test_config_service.py       ğŸ†• NEW
â”‚   â””â”€â”€ test_library_service.py      ğŸ†• NEW
â”œâ”€â”€ database/
â”‚   â””â”€â”€ test_database.py             ğŸ†• NEW
â”œâ”€â”€ ai/
â”‚   â”œâ”€â”€ test_prompts.py              ğŸ†• NEW
â”‚   â””â”€â”€ test_pdf_generator.py        ğŸ†• NEW
â””â”€â”€ integration/
    â”œâ”€â”€ test_digital_twin_flow.py    ğŸ†• NEW
    â””â”€â”€ test_session_lifecycle.py    ğŸ†• NEW
```

**Focus Areas:**
- **Critical Business Logic:** History queries, setup parsing, drift analysis
- **Data Transformations:** CSVâ†”JSONB, PDF fieldsâ†’schema mapping
- **Edge Cases:** Missing parameters, invalid inputs, network failures

**Testing Strategy:**
- **Unit Tests:** Isolated function testing with mocks
- **Integration Tests:** Database interactions, service coordination
- **End-to-End Tests:** Skip for now (too expensive)

**Example Test (NEW):**
```python
# tests/services/test_history_service.py
import pytest
from Execution.services.history_service import get_successful_changes

def test_get_successful_changes_returns_improvements(mock_db):
    """Test that successful changes are sorted by lap time improvement."""
    changes = get_successful_changes(
        track_name="Thunder Alley",
        traction_level="High",
        limit=5
    )

    assert len(changes) <= 5
    assert all(c["improvement"] > 0 for c in changes)
    # Should be sorted descending
    assert changes[0]["improvement"] >= changes[-1]["improvement"]

def test_get_successful_changes_excludes_failures(mock_db):
    """Test that changes marked as failures are excluded."""
    changes = get_successful_changes(track_name="Thunder Alley")

    assert all(c["x_factor_rating"] >= 3 for c in changes)
```

#### 2.2 Add Integration Tests
**Purpose:** Test service interactions and database operations

**Key Scenarios:**
1. **Digital Twin Lifecycle:**
   - Load baseline â†’ Apply AI recommendation â†’ Track drift â†’ Close session with X-Factor
2. **Setup Parsing Pipeline:**
   - Upload PDF â†’ Extract fields â†’ Map to schema â†’ Save to library
3. **Institutional Memory:**
   - Create session â†’ Log changes â†’ Query history â†’ Generate AI context

**Tooling:**
```bash
pip install pytest-asyncio
```

**Fixture Strategy:**
```python
# tests/conftest.py
@pytest.fixture
def test_database():
    """Provide isolated test database for integration tests."""
    # Use SQLite in-memory for fast tests
    db = create_test_database()
    yield db
    db.cleanup()

@pytest.fixture
def sample_setup():
    """Provide valid 24-parameter setup for testing."""
    return {
        "DF": "7000", "DC": "5000", "DR": "3000",
        "SO_F": "450", "SP_F": "700", "SB_F": "1.3",
        # ... all 24 parameters
    }
```

#### 2.3 Testing Documentation
**Create:** `tests/README.md`

**Contents:**
- How to run tests locally
- How to write new tests
- Mocking strategy for external services (Anthropic API, OpenAI API)
- CI/CD integration details
- Coverage reporting

---

### Task 3: Code Quality Automation
**Why:** Maintain consistent code style, catch bugs before review, reduce cognitive load

**Effort:** 1-2 hours
**Priority:** HIGH

#### 3.1 Pre-Commit Hooks
**Tool:** `pre-commit` framework

**Install:**
```bash
pip install pre-commit
```

**Create:** `.pre-commit-config.yaml`
```yaml
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.1.9
    hooks:
      - id: ruff
        args: [--fix, --exit-non-zero-on-fix]
      - id: ruff-format

  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-added-large-files
        args: ['--maxkb=1000']
      - id: check-merge-conflict
      - id: detect-private-key

  - repo: https://github.com/pycqa/isort
    rev: 5.13.2
    hooks:
      - id: isort
        args: ["--profile", "black"]

  - repo: https://github.com/pycqa/pydocstyle
    rev: 6.3.0
    hooks:
      - id: pydocstyle
        args: ["--convention=google"]
        # Only runs on staged files, not entire codebase

  - repo: local
    hooks:
      - id: pytest-check
        name: Run pytest
        entry: pytest tests/ -v --tb=short -x
        language: system
        pass_filenames: false
        always_run: false  # Only run if tests/ directory changes
        files: ^tests/
```

**Setup:**
```bash
pre-commit install
# Now runs automatically on every commit
```

**Manual Run:**
```bash
pre-commit run --all-files
```

#### 3.2 Ruff Configuration
**Create:** `pyproject.toml`
```toml
[tool.ruff]
line-length = 100
target-version = "py310"

[tool.ruff.lint]
select = [
    "E",   # pycodestyle errors
    "W",   # pycodestyle warnings
    "F",   # pyflakes
    "I",   # isort
    "N",   # pep8-naming
    "B",   # flake8-bugbear
    "SIM", # flake8-simplify
    "C4",  # flake8-comprehensions
]
ignore = [
    "E501",  # line too long (let black handle this)
    "B008",  # do not perform function calls in argument defaults
]

[tool.ruff.lint.per-file-ignores]
"__init__.py" = ["F401"]  # Unused imports in __init__.py

[tool.black]
line-length = 100
target-version = ["py310"]

[tool.isort]
profile = "black"
line_length = 100

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = "-v --tb=short --strict-markers"
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "integration: marks tests as integration tests",
]

[build-system]
requires = ["setuptools>=65.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "apex-agr-system"
version = "1.7.1"
description = "A.P.E.X. - Accelerate Performance + Experimentation = X-Factor"
requires-python = ">=3.10"

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "pytest-mock>=3.11.1",
    "ruff>=0.1.9",
    "black>=23.12.0",
    "isort>=5.13.0",
    "pre-commit>=3.5.0",
]
```

#### 3.3 Automated Dependency Updates
**Tool:** Dependabot (GitHub-native)

**Create:** `.github/dependabot.yml`
```yaml
version: 2
updates:
  - package-ecosystem: "pip"
    directory: "/"
    schedule:
      interval: "weekly"
    open-pull-requests-limit: 10
    labels:
      - "dependencies"
      - "automated"
    commit-message:
      prefix: "chore"
      include: "scope"
```

**Benefits:**
- Automatic PRs for dependency updates
- Security vulnerability alerts
- One-click merge for non-breaking updates

#### 3.4 Security Scanning
**Tools:**
- `bandit` - Python security linter
- `safety` - Dependency vulnerability scanner

**Add to CI/CD:**
```yaml
# .github/workflows/ci.yml (add new job)
security:
  name: Security Scanning
  runs-on: ubuntu-latest

  steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install security tools
      run: |
        pip install bandit safety

    - name: Run Bandit (security linter)
      run: bandit -r Execution/ -f json -o bandit-report.json
      continue-on-error: true

    - name: Run Safety (dependency vulnerabilities)
      run: safety check --json > safety-report.json
      continue-on-error: true

    - name: Upload security reports
      uses: actions/upload-artifact@v3
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
```

---

### Task 4: Monitoring and Observability
**Why:** Debug production issues faster, catch errors before users report them

**Effort:** 1-2 hours
**Priority:** HIGH (Error Tracking), LOW (Performance Monitoring, Usage Analytics)

**IMPORTANT:** Prioritize error tracking first. Performance monitoring and usage analytics are lower priority unless actively experiencing slowdowns.

#### 4.1 Structured Logging
**Current State:** Inconsistent `print()` and `st.write()` statements
**Target State:** Standardized structured logging

**Create:** `Execution/utils/logging.py`
```python
import logging
import sys
from pathlib import Path

def setup_logging(log_level: str = "INFO") -> logging.Logger:
    """Configure structured logging for A.P.E.X."""

    logger = logging.getLogger("apex")
    logger.setLevel(getattr(logging, log_level.upper()))

    # Console handler (stdout)
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)

    # File handler (persistent logs)
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    file_handler = logging.FileHandler(log_dir / "apex.log")
    file_handler.setLevel(logging.DEBUG)

    # Structured format
    formatter = logging.Formatter(
        '{"timestamp": "%(asctime)s", "level": "%(levelname)s", '
        '"module": "%(name)s", "message": "%(message)s", '
        '"function": "%(funcName)s", "line": %(lineno)d}',
        datefmt='%Y-%m-%d %H:%M:%S'
    )

    console_handler.setFormatter(formatter)
    file_handler.setFormatter(formatter)

    logger.addHandler(console_handler)
    logger.addHandler(file_handler)

    return logger

# Usage:
from Execution.utils.logging import setup_logging
logger = setup_logging()

logger.info("Session started", extra={
    "track": "Thunder Alley",
    "vehicle": "NB48_2.2",
    "user_id": "racer_123"
})
```

**Migration Strategy:**
```python
# OLD:
print(f"Parsing setup sheet: {brand}")

# NEW:
logger.info("Parsing setup sheet", extra={"brand": brand, "pdf_path": pdf_path})
```

#### 4.2 Error Tracking Integration â­ PRIORITY
**Tool:** Sentry (free tier: 5k events/month)

**Why This First:**
- Knowing WHEN it crashes > knowing HOW FAST it runs
- Most valuable observability tool for current stage
- Catches production errors you wouldn't see otherwise

**Setup:**
```bash
pip install sentry-sdk
```

**Configuration:**
```python
# config/settings.py
import sentry_sdk

if os.getenv("SENTRY_DSN"):
    sentry_sdk.init(
        dsn=os.getenv("SENTRY_DSN"),
        environment=os.getenv("ENVIRONMENT", "production"),
        # Disable performance monitoring initially (focus on errors)
        traces_sample_rate=0.0,
        # Enable error tracking only
        before_send=lambda event, hint: event if event.get("exception") else None,
    )
```

**Benefits:**
- Automatic error capture with full stack traces
- Context: user, session, setup parameters
- Email/Slack alerts for critical errors
- Release tracking (correlate errors with deployments)

**Add to `.env.example`:**
```bash
# Optional: Error tracking (Sentry - FREE tier recommended)
SENTRY_DSN=https://your-sentry-dsn-here
```

**Note:** Start with error tracking only. Add performance monitoring later if you identify specific slowness issues.

#### 4.3 Performance Monitoring (OPTIONAL - Lower Priority)
**Skip This Unless:** You're actively experiencing slowdowns or user complaints

**Why Low Priority:**
- No current performance issues reported
- AI response times are inherently variable (depends on Anthropic API)
- Adds complexity without clear value at current scale

**If Needed Later:**
Add simple timing logs to critical operations:

```python
import time
import logging

logger = logging.getLogger("apex")

def parse_setup_sheet(pdf_path: str, brand: str) -> dict:
    start = time.time()
    try:
        # ... parsing logic
        result = {...}
        duration = time.time() - start
        logger.info(f"Setup parsing completed in {duration:.2f}s", extra={
            "brand": brand,
            "duration_ms": int(duration * 1000)
        })
        return result
    except Exception as e:
        logger.error(f"Setup parsing failed after {time.time() - start:.2f}s")
        raise
```

**Recommendation:** Only add if you identify specific slowness through user feedback or Sentry alerts.

#### 4.4 Usage Analytics (OPTIONAL - Lowest Priority)
**Goal:** Understand feature adoption (only if you need it)

**Recommendation:** Skip this initially. Focus on building features, not measuring usage.

**Why Low Priority:**
- Single user / small user base doesn't need analytics
- Natural feedback through direct user interaction
- Adds development overhead without clear ROI
- Premature optimization of product development

**If Needed Later (Multi-User Phase):**
- Use existing database tables (sessions, track_logs, x_factor_audits)
- Simple SQL queries provide all insights needed
- No additional infrastructure required

```sql
-- Example analytics queries
SELECT COUNT(*) as total_sessions FROM sessions;
SELECT vehicle_id, COUNT(*) as session_count FROM sessions GROUP BY vehicle_id;
SELECT AVG(rating) as avg_rating FROM x_factor_audits;
```

**Decision:** Skip for now, revisit in Phase 4.2 (Multi-Driver Sync) when user base grows.

---

### Task 5: Developer Experience Improvements
**Why:** Faster onboarding, consistent environments, reduced friction

**Effort:** 1-2 hours
**Priority:** LOW (nice-to-have)

#### 5.1 Makefile for Common Operations
**Create:** `Makefile`

```makefile
.PHONY: help install test lint format run clean

help: ## Show this help message
	@echo "Usage: make [target]"
	@echo ""
	@echo "Targets:"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "  %-20s %s\n", $$1, $$2}'

install: ## Install dependencies
	pip install -r requirements.txt

install-dev: ## Install development dependencies
	pip install -r requirements.txt
	pip install -e ".[dev]"
	pre-commit install

test: ## Run tests
	pytest tests/ -v --cov=Execution --cov-report=term --cov-report=html

test-fast: ## Run tests (skip slow tests)
	pytest tests/ -v -m "not slow"

lint: ## Run linters
	ruff check Execution/ --fix
	black --check Execution/
	isort --check Execution/

format: ## Format code
	ruff check Execution/ --fix
	black Execution/
	isort Execution/

run: ## Run dashboard locally
	streamlit run Execution/dashboard.py

clean: ## Clean temporary files
	find . -type d -name __pycache__ -exec rm -rf {} +
	find . -type f -name "*.pyc" -delete
	rm -rf .pytest_cache htmlcov .coverage
	rm -rf logs/*.log

migrate: ## Run database migrations
	python Execution/database/migrate_to_database.py

docs: ## Build documentation
	mkdocs build

docs-serve: ## Serve documentation locally
	mkdocs serve
```

**Usage:**
```bash
make help          # Show all targets
make install-dev   # Set up development environment
make test          # Run tests
make format        # Format code
make run           # Start dashboard
```

#### 5.2 VS Code Workspace Settings
**Create:** `.vscode/settings.json`

```json
{
  "python.defaultInterpreterPath": "${workspaceFolder}/.venv/bin/python",
  "python.linting.enabled": true,
  "python.linting.ruffEnabled": true,
  "python.formatting.provider": "black",
  "editor.formatOnSave": true,
  "editor.codeActionsOnSave": {
    "source.organizeImports": true
  },
  "[python]": {
    "editor.rulers": [100],
    "editor.tabSize": 4
  },
  "files.exclude": {
    "**/__pycache__": true,
    "**/*.pyc": true,
    ".pytest_cache": true,
    "htmlcov": true,
    ".coverage": true
  },
  "python.testing.pytestEnabled": true,
  "python.testing.unittestEnabled": false,
  "python.testing.pytestArgs": [
    "tests",
    "-v"
  ]
}
```

**Create:** `.vscode/extensions.json`
```json
{
  "recommendations": [
    "ms-python.python",
    "ms-python.vscode-pylance",
    "charliermarsh.ruff",
    "ms-python.black-formatter",
    "streetsidesoftware.code-spell-checker",
    "eamodio.gitlens"
  ]
}
```

#### 5.3 Docker Containerization (OPTIONAL - Consider Windows Compatibility)
**âš ï¸ Windows Consideration:** Ensure Docker Desktop is viable for your workflow before committing

**Current Workflow (Recommended):**
- Robust `venv` or `conda` environment
- `requirements.txt` or `pyproject.toml` for dependencies
- Railway handles containerization in production automatically

**When Docker Makes Sense:**
- Multiple developers on different OSes (Mac/Linux/Windows)
- Complex system dependencies (database, Redis, etc.)
- Deployment requires exact environment replication

**If You Still Want Docker:**

**Create:** `Dockerfile`
```dockerfile
FROM python:3.10-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    poppler-utils \
    && rm -rf /var/lib/apt/lists/*

# Copy dependency files
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY Directives/ Directives/
COPY Orchestration/ Orchestration/
COPY Execution/ Execution/
COPY Data/ Data/
COPY config/ config/
COPY .env.example .env

# Expose Streamlit port
EXPOSE 8501

# Run dashboard
CMD ["streamlit", "run", "Execution/dashboard.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

**Create:** `docker-compose.yml` (local development with PostgreSQL)
```yaml
version: '3.8'

services:
  apex:
    build: .
    ports:
      - "8501:8501"
    environment:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - DATABASE_URL=postgresql://apex:apex@db:5432/apex
    volumes:
      - ./Execution:/app/Execution  # Hot reload for development
      - ./logs:/app/logs
    depends_on:
      - db

  db:
    image: postgres:15-alpine
    environment:
      - POSTGRES_USER=apex
      - POSTGRES_PASSWORD=apex
      - POSTGRES_DB=apex
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  postgres_data:
```

**Windows-Specific Notes:**
- Requires Docker Desktop (Windows 10/11 Pro or WSL2)
- Volume mounts can be slow on Windows
- Alternative: Use WSL2 directly + Railway for production

---

## Implementation Order (Revised - Practical Priorities)

Execute tasks in this sequence:

### Phase 1: Core Quality Infrastructure (HIGH PRIORITY)
1. âœ… **Task 3.1:** Pre-commit hooks (quick win, immediate benefit)
2. âœ… **Task 3.2:** Ruff + pyproject.toml configuration
3. âœ… **Task 3.3:** Dependabot configuration (automated security)
4. âœ… **Task 4.2:** Sentry error tracking â­ (know when it crashes)
5. âœ… **Task 4.1:** Structured logging setup

### Phase 2: Testing & Documentation (MEDIUM PRIORITY)
6. âœ… **Task 2.1:** Expand unit test coverage (target 40-60%, gradual)
7. âœ… **Task 1.1:** Docstring leak-proof policy (new/modified files only)
8. âœ… **Task 1.3:** Architecture Decision Records (3-5 initial ADRs)
9. âœ… **Task 2.2:** Integration tests for critical flows

### Phase 3: Documentation Site (LOWER PRIORITY)
10. â­ï¸ **Task 1.2:** MkDocs documentation (when time permits)
11. â­ï¸ **Task 1.4:** Contributor onboarding guide

### Phase 4: Developer Experience (OPTIONAL)
12. â­ï¸ **Task 5.1:** Makefile for common operations
13. â­ï¸ **Task 5.2:** VS Code workspace settings
14. â­ï¸ **Task 5.3:** Docker containerization (skip unless needed)

### SKIP (Not Valuable at Current Stage)
- âŒ **Task 4.3:** Performance monitoring (no active slowdowns)
- âŒ **Task 4.4:** Usage analytics (small user base)

---

## Testing Checklist (Revised - Practical Goals)

### Phase 1 Complete (Core Quality):
- [ ] Pre-commit hooks installed and working on new commits
- [ ] Ruff and Black configured in `pyproject.toml`
- [ ] Dependabot enabled for automated dependency PRs
- [ ] Sentry DSN configured (even if just for local testing)
- [ ] Structured logging module created (`Execution/utils/logging.py`)
- [ ] GitHub Actions CI/CD includes security scanning

### Phase 2 Complete (Testing & Docs):
- [ ] `pytest tests/` passes with >40% coverage (realistic baseline)
- [ ] Docstring policy enforced on new/modified files only
- [ ] 3-5 ADRs written for major architectural decisions
- [ ] Integration test for at least one critical flow (Digital Twin)
- [ ] Dashboard still runs correctly after all changes

### Phase 3 Complete (Documentation Site):
- [ ] MkDocs configuration created
- [ ] At least 5 documentation pages written (index, quickstart, 3 guides)
- [ ] `mkdocs serve` runs locally without errors
- [ ] Contributor guide created

### Phase 4 Complete (Developer Experience):
- [ ] Makefile with common operations (test, lint, format, run)
- [ ] VS Code settings for consistent formatting
- [ ] (Optional) Docker setup tested on your Windows environment

---

## Expected Benefits (Realistic Outcomes)

### Code Quality (High Value)
- âœ… Catch bugs before commit (pre-commit hooks)
- âœ… Maintain consistent style automatically (ruff, black)
- âœ… Identify security vulnerabilities early (Dependabot, bandit)
- âœ… Gradual improvement in code documentation (leak-proof docstrings)

### Production Reliability (Critical Value)
- âœ… **Know when it crashes** (Sentry error tracking) â­ MOST VALUABLE
- âœ… Debuggable issues with context (structured logging)
- âœ… Automated security patches (Dependabot)
- âœ… CI/CD catches issues before deployment

### Developer Experience (Medium Value)
- âœ… Faster onboarding (contributor guide, ADRs)
- âœ… Confidence in changes (test coverage)
- âœ… Clear architectural history (ADRs)
- âœ… Common operations automated (Makefile)

### Long-Term Maintainability (Growing Value Over Time)
- âœ… Searchable knowledge base (MkDocs docs)
- âœ… Documented decisions prevent re-litigating (ADRs)
- âœ… Regression prevention (integration tests)
- âœ… Gradual documentation coverage (leak-proof policy)

---

## Budget Considerations

**Free Tier Tools (Recommended):**
- GitHub Actions: 2,000 minutes/month (free for public repos)
- Sentry: 5,000 errors/month
- Dependabot: Free (GitHub-native)
- MkDocs + GitHub Pages: Free static site hosting

**Cost:** $0/month for all tooling

**Time Investment:**
- Initial setup: 4-6 hours
- Ongoing maintenance: ~30 minutes/week (review Dependabot PRs, check CI/CD)

---

## Success Metrics

**After 1 Month:**
- 40%+ test coverage (realistic baseline)
- 0 ruff/black violations on new code
- 3-5 ADRs documenting major decisions
- Docstrings on all new/modified functions

**After 3 Months:**
- 95% of commits pass pre-commit hooks on first try
- 0 critical security vulnerabilities (Dependabot alerts addressed)
- Sentry catching production errors before user reports
- 50%+ test coverage through gradual additions

**After 6 Months:**
- 60%+ test coverage
- 50%+ reduction in production errors (via Sentry insights)
- Complete MkDocs documentation site live
- Zero high-severity dependency vulnerabilities
- Contributor onboarding takes <1 hour (using docs)

---

## Non-Goals (Out of Scope)

This plan intentionally DOES NOT include:

- âŒ End-to-end UI testing (Selenium, Playwright) - too expensive for ROI
- âŒ Load testing / stress testing - not needed at current scale
- âŒ Multiple staging environments - single production deployment sufficient
- âŒ Feature flags / A/B testing - premature for current user base
- âŒ Comprehensive API documentation (OpenAPI/Swagger) - no public API
- âŒ i18n/l10n (internationalization) - English-only for now
- âŒ Mobile app development - web-first strategy
- âŒ Performance monitoring unless actively experiencing slowdowns
- âŒ Usage analytics until multi-user phase

---

## Commit Message Template

```
feat: Priority 3 - Advanced Development Practices & Quality Engineering

Phase 1 - Core Quality Infrastructure:
1. Pre-commit hooks with ruff, black, isort, pydocstyle
2. Comprehensive pyproject.toml with tool configurations
3. Structured logging framework (Execution/utils/logging.py)
4. GitHub Actions security scanning (bandit, safety)
5. Dependabot automated dependency updates
6. Sentry error tracking integration

Phase 2 - Testing & Documentation:
1. Unit test coverage expansion (services/database/ai layers)
2. Integration tests for critical flows (Digital Twin, X-Factor)
3. Google-style docstrings (leak-proof policy: new/modified files only)
4. Architecture Decision Records (3-5 initial ADRs)
5. Testing documentation (tests/README.md)

Phase 3 - Documentation Site (Optional):
1. MkDocs configuration with Material theme
2. API reference documentation
3. User guides and tutorials
4. Contributor onboarding guide

Phase 4 - Developer Experience (Optional):
1. Makefile for common operations
2. VS Code workspace settings and extensions
3. (Windows-aware Docker setup if needed)

Benefits:
- Automated code quality enforcement (pre-commit + CI/CD)
- Know when it crashes (Sentry error tracking) â­
- Catch bugs before production
- Gradual documentation improvement (leak-proof policy)
- Performance and error monitoring
- Zero-cost tooling (all free tier)

Philosophy:
- "Leak-proof" documentation: enforce on new code only
- Error tracking first: WHEN > HOW FAST
- Pragmatic testing: 40-60% coverage goal
- Skip analytics until multi-user phase

Testing:
- All pre-commit hooks pass
- Test coverage increased from 20% â†’ 40%+
- Dashboard runs without errors
- CI/CD pipeline passes all checks

ğŸ¤– Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude Sonnet 4.5 <noreply@anthropic.com>
```

---

## Related Documentation

- Priority 1: Feature implementation (COMPLETE)
- Priority 2: Project structure refactoring (`priority_2_refactoring_plan.md`) âœ… COMPLETE
- Priority 3: THIS DOCUMENT
- Testing Guide: `tests/README.md` (to be created)
- Architecture Decisions: `docs/architecture/decisions/` (to be created)
- Deployment Guide: `Orchestration/Deployment/RAILWAY_DEPLOYMENT.md` (existing)

---

**Status:** ğŸ“‹ PLANNED - Ready for implementation when approved
**Dependencies:** Priority 2 âœ… COMPLETE
**Next Step:** User approval to proceed with Phase 1 (Pre-commit hooks + Configuration + Sentry)
